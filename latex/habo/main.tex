%!TeX program = LuaLaTeX 
\documentclass{article}
\usepackage[top=2.5cm, bottom=2.5cm, left=3cm, right=3cm]{geometry}
\usepackage{caption}
\usepackage[numbers]{natbib}
\usepackage{bm}
\usepackage{parskip}
\usepackage{dirtytalk}
\usepackage{float}
\usepackage[
  product-units=single
]{siunitx}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{lipsum}
\usepackage[nolist,nohyperlinks]{acronym}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{tkz-graph}
\usepackage{float}
\usepackage{mathrsfs}
\usepackage{pgfplots}
\usepackage{caption}
\usepackage{amsthm}
\usepackage{calc}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{titlesec}

\usepackage{fontspec}
\usepackage{mathtools} 
\usepackage[
  warnings-off={
    mathtools-colon,
    mathtools-overbracket
  }
]{unicode-math}
\usepackage{amsthm}     

\setmainfont{Charter}
\setmathfont{LatinModern Math}
%\setmathfont{XCharter-Math}
%\setmathfont{XITS Math}
\usetikzlibrary{calc}
\usetikzlibrary{arrows}

\usepackage[colorlinks=false,hidelinks]{hyperref}

\usepackage{../shared/general}

\newfontfamily{\ImperialSans}{Imperial Sans Text}[
  UprightFont=*-Medium,
  BoldFont=*-Bold,
]
\newfontface{\ImperialSansExtraBold}{Imperial Sans Text Extrabold}
\newfontface{\ImperialSansBold}{Imperial Sans Text Bold}
\newfontface{\ImperialSansExtraLight}{Imperial Sans Text Extralight}
\newfontface{\ImperialSansSemiBold}{Imperial Sans Text Semibold}
\newfontface{\ImperialSansLight}{Imperial Sans Text Light}

\pgfplotsset{compat=1.18}
\titleformat{\section}[hang]
{\ImperialSansSemiBold\large}
{\thesection}
{1em}
{\hspace{-0.4pt}\large}

\titleformat{\subsection}[hang]
{\ImperialSansSemiBold}
{\thesection}
{1em}
{\hspace{-0.4pt}}

\titleformat{\subsubsection}[hang]
{\ImperialSans}
{\thesection}
{1em}
{\hspace{-0.4pt}}


\title{\ImperialSansBold Hierarchy Aware Gaussian Processes\Huge}
%\date{9\superscript{th} October 2025}
\date{}
\author{
	\begin{tabular}{@{}l@{\hspace{0.8cm}}r@{}}
    Joseph Whitaker Schaefer & j.schaefer24@imperial.ac.uk \\
	\end{tabular}
}


%\pagenumbering{gobble}

% remove indentation
\setlength{\parindent}{0pt}

\newcommand{\xellind}[2]{{\vct{x}^{#1}_{#2}}}
\newcommand{\yellind}[2]{{y^{#1}_{#2}}}


\newcommand{\forrester}[1]{((6*(#1) - 2)^2 * sin(deg(12*(#1) - 4)))}
\newcommand{\mfforrester}[4]{((#2*\forrester{#1}) + (#3 * (#1-0.5)) - #4)}

\newcommand{\veryshortarrow}[1][3pt]{\mathrel{%
   \hbox{\rule[\dimexpr\fontdimen22\textfont2-.2pt\relax]{#1}{.4pt}}%
   \mkern-4mu\hbox{\usefont{U}{lasy}{m}{n}\symbol{41}}}}

\makeatletter

\setbox0\hbox{$\xdef\scriptratio{\strip@pt\dimexpr
    \numexpr(\sf@size*65536)/\f@size sp}$}

\newcommand{\scriptveryshortarrow}[1][3pt]{{%
    \hbox{\rule[\scriptratio\dimexpr\fontdimen22\textfont2-.2pt\relax]
               {\scriptratio\dimexpr#1\relax}{\scriptratio\dimexpr.4pt\relax}}%
   \mkern-4mu\hbox{\let\f@size\sf@size\usefont{U}{lasy}{m}{n}\symbol{41}}}}

\makeatother
\newcommand{\direct}[3]{{#1_{#2 \,\scriptveryshortarrow #3}}}
\newcommand{\wvct}[3]{{\direct{\vct{w}^{#1}}{#2}{#3}}}

\input{acronyms}


\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

\bibliographystyle{IEEEtran}

\begin{document}
\maketitle
\section*{Introduction}
\textit{Thesis}\newline
Fusion of information from different sources can be used to augment estimates of expensive sources using observations from cheaper sources.
Existing approaches enable this by encoding model dependencies.

\textit{Antithesis}\newline
Existing approaches assume a strict model hierarchy.
Examples exist where this hierarchy breaks down.

\textit{Synthesis}\newline
We can frame the problem as one of mean and kernel learning by encoding model hierarchies into the mean and covariance functions of a single analytically tractable GP with additional hyperparameters.

\section*{Source Hierarchies}
A source hierarchy \(H\) can be described as a \ac{dag} with a set of vertices \(V\) representing information sources, and edges \(E\) showing relationships in the accuracy of one source relative to the next, which may be known or assumed \textit{a priori}.
\[
	H = (V, E) \qquad
	V = \{\source_i\}_{i=1}^L \qquad
	E \subseteq V \times V \qquad
	(u,v) \in E \Rightarrow u \rightarrow v
\]
Each \ac{dag} has a set of directed paths \(P\), each member of which is an ordered set of edges in \(E\).
One may traverse from the first vertex \(a\) to the last vertex \(d\) following the edges in order.
\[
	P = \{ \{(a,\,\cdot\,), \dots, (\,\cdot\,,d)\} \given (a,d) \in E^+ \}
\]
For a path \(Q\) in \(P\) there exists a set of sub-paths \(R\) joining each of the vertices that constitute the edges in \(Q\). From this definition it is clear that a sub-path \(\direct{R}{a}{b}\) joining vertices \(a_a\) and \(v_b\) is either equivalent to \(Q\), or a truncation of \(Q\).

\section*{Cross-Source Correlation}
We seek to define a covariance function \(k\) that considers the context of the source hierarchy.
We assume that observations two sources are correlated when the estimate of one source improves upon the other.
In terms of the hierarchy, this corresponds to a directed path existing between the sources.
The covariance of two observations at inputs \(\vct{x}\) and \(\vct{x}'\) becomes a function of the source fidelities \(\ell\) and \(\ell'\) and the source hierarchy.
The requirement that the source be connected by a directed path means that the value of this function may only be non-zero if and only if the path exists.
\[
	k((\vct{x}, \ell), (\vct{x}', \ell'); H) \ne 0 \iff \source_\ell \rightsquigarrow \source_{\ell'}  \vee \source_{\ell'} \rightsquigarrow \source_{\ell}
\]

\subsection*{Adjacent Fidelity Case}
\ac{gp} based approaches to estimating the response of a higher-fidelity source \(\source_{\ell}\) given observations from a lower-fidelity source \(\source_{\ell-1}\) involve modelling the discrepancy \(\delta_\ell\) between the mapped lower-fidelity representation \(z_{\ell-1}(f_{\ell-1})\) and the higher-fidelity observations \cite{perdikarisNonlinearInformationFusion2017}.
\[
	f_\ell = z_{\ell-1}(f_{\ell-1}) + \delta_\ell \qquad
	\delta_\ell \sim \gp{m_{\delta_\ell}, k_{\delta_\ell}}
\]
\input{figures/adjacent_source_dag}
Considering first the case where \(z_t\) takes the form proposed by O'Hagan, and \(z_\ell(x) = \varrho_\ell x\).
In this approach, the influence of observations from \(\source_{\ell-1}\) on the posterior of \(f_\ell\) is governed entirely by the hyperparameter \(\varrho\), which may be shown as follows.

Consider two independent \acp{gp} \(g_1\) and \(g_2\).
\[
	g_1 \sim \symcal{GP}(m_1, k_1) \quad
	g_2 \sim \gp{m_2, k_2} \quad
	g_1 \bot g_2
\]
the result of their weighted sum is
\[
	g = \alpha f_1 + \beta f_2 \quad
	\Leftrightarrow \quad
	g \sim \symcal{GP}(\alpha m_1 + \beta m_2, \alpha^2k_1 + \beta^2k_2)
\]

This property allows \(f_\ell\) to be written as
\[
	f_\ell \sim \gp{m_\ell, k_\ell} \qquad m_\ell = m_{\delta_\ell} + \varrho_{\ell-1}m_{\ell-1} \qquad k_\ell = k_{\delta_\ell} + \varrho^2_{\ell-1} k_{\ell-1}
\]
From this, any linear combination of \acp{gp} may be interpreted as a single \ac{gp} with an analytical posterior, the mean and covariance functions of which are defined through linear sums of the constituent mean and covariance functions \(\vct{m}_\delta\) and \(\vct{k}_\delta\). We use this to express the correlation between observations from adjacent fidelities as
\begin{align*}
	 & m_\ell((x, \ell))              = \langle \vct{m}_\delta, \vct{w}^m_{\ell-1, \ell}  \rangle \\
	 & k_\ell((x, \ell), (x', \ell-1))  = \langle \vct{k}_\delta, \vct{w}_{\ell-1,\ell}  \rangle
\end{align*}
where
\begin{align*}
	\vct{m}_\delta & = \begin{bmatrix}  m_{\delta_\ell}(x) & m_{\ell-1}(x) \end{bmatrix} & \vct{w}^m_{\ell-1, \ell} = \begin{bmatrix} 1 & \varrho_{\ell-1}  \end{bmatrix} \\
	\vct{k}_\delta & = \begin{bmatrix}  k_{\delta_\ell}(x) & k_{\ell-1}(x) \end{bmatrix} & \vct{w}_{\ell-1,\ell} = \begin{bmatrix} 1 & \varrho_{\ell-1}^2 \end{bmatrix}   \\
\end{align*}
\input{figures/xfc_forrester}

\section*{Generalised Formulation}
We introduce a pair of weight matrices \(\mat{W}_m\) and \(\mat{W}_k\) where each entry \(w_{u \, \scriptveryshortarrow v, i}\) is the linear weight associated with the respective mean and covariance of the representation at fidelity \(i\) for observations at fidelities \(u\) and \(v\).

Extending to \(L\) many sources with an arbitrary hierarchy we consider that the correlation between observations from \(\source_u\) and \(\source_v\) is influenced by all passible directed paths \(\direct{P}{u}{v} \subseteq P\) between them.
\begingroup
\renewcommand*{\arraystretch}{1.5}
\begin{align*}
	\mat{W}_m(H)                          & = \begin{bmatrix}
		                                          \wvct{m}{1}{1} \\
		                                          \vdots         \\
		                                          \wvct{m}{1}{L} \\
	                                          \end{bmatrix}                                                                                               &
	\mat{W}_k(H)                          & = \begin{bmatrix}
		                                          \wvct{k}{1}{1} & \dots  & \wvct{k}{L}{1} \\
		                                          \vdots         & \ddots & \vdots         \\
		                                          \wvct{k}{1}{L} & \dots  & \wvct{k}{L}{L} \\
	                                          \end{bmatrix}                                                                        \\
	\vspace{1em}                                                                                                                                              \\
	w^m_{u \, \scriptveryshortarrow v, i} & = \sum_{Q\,\in\,\direct{P}{u}{v}} \, \prod_{(a,b) \, \in \, \direct{R}{i}{v} \given Q} \direct{\varrho}{a}{b}   &
	w^k_{u \, \scriptveryshortarrow v, i} & = \sum_{Q\,\in\,\direct{P}{u}{v}} \, \prod_{(a,b) \, \in \, \direct{R}{i}{v} \given Q} \direct{\varrho^2}{a}{b}
\end{align*}
\endgroup

The generalised cross-fidelity mean and covariance functions are then
\[
	m((x,\ell) \given H) = \langle \vct{m}_\delta, \wvct{m}{1}{\ell}  \rangle  \qquad
	k((\vct{x}, \ell), (\vct{x}', \ell') \given H) = \langle \vct{k}_\delta,\wvct{k}{\min(\ell, \ell')}{\max(\ell,\ell')}  \rangle
\]
Derivation would be nice.

\section*{Auto-Regressive Example}
Kennedy and O'Hagan introduce an autoregressive scheme to combine information from sources with differing fidelities \cite{kennedyPredictingOutputComplex2000}.
\[
	f_1 \sim \gp{m_{\delta_1}, k_{\delta_1}} \qquad f_\ell = \varrho_{\ell-1} f_{\ell-1} + \delta_\ell \quad \ell \in \{2. \dots, L\} \qquad \delta_\ell \sim \symcal{GP}(m_{\delta_\ell}, k_{\delta_\ell})
\]
This formulation implies that a given source \(\source_{\ell+1}\) provides a better estimate of the highest fidelity source \(\source_L\) than its child \(\source_{\ell}\), resulting in the following hierarchy, show in figure \ref{fig:armfgp}.
\[
	V_\text{AR} = \{\source_\ell\}^{L}_{\ell=1} \qquad
	E_\text{AR} = \{(\source_{\ell},   \source_{\ell+1})\}^{L-1}_{\ell = 1} \qquad
	%\source_\ell : \mathcal{X} \rightarrow \mathcal{Y}
\]
\input{figures/auto_dag}

\bibliography{references/GPS}
\end{document}

